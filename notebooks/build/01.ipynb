{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "path = os.getcwd()\n",
    "while os.path.basename(os.path.normpath(path)) != 'mejiro':\n",
    "    path = os.path.dirname(path)\n",
    "repo_path = path\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from glob import glob\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from multiprocessing import Pool\n",
    "from hydra import initialize, compose\n",
    "import pickle\n",
    "\n",
    "from mejiro.lenses.lens import Lens\n",
    "from mejiro.plots import diagnostic_plot, plot\n",
    "from mejiro.utils import util\n",
    "from mejiro.scripts import generate\n",
    "from mejiro.helpers import pyhalo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lens(row):\n",
    "    row_dict = dict(row)\n",
    "    return Lens(z_lens=row_dict['redslens'],\n",
    "                z_source=row_dict['redssour'],\n",
    "                theta_e=row_dict['angleins'],\n",
    "                lens_x=row_dict['xposlens'],\n",
    "                lens_y=row_dict['yposlens'],\n",
    "                source_x=row_dict['xpossour'],\n",
    "                source_y=row_dict['ypossour'],\n",
    "                mag_lens=row_dict['magtlensF106'],\n",
    "                mag_source=row_dict['magtsourF106'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path='../../config'):\n",
    "    config = compose(config_name='config.yaml')  # overrides=['machine=uzay']\n",
    "\n",
    "array_dir, data_dir, repo_dir, pickle_dir = config.machine.array_dir, config.machine.data_dir, config.machine.repo_dir, config.machine.pickle_dir\n",
    "util.create_directory_if_not_exists(pickle_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get output of SkyPy pipeline\n",
    "df = pd.read_csv(os.path.join('/data','bwedig', 'roman-population', 'data', 'dictparaggln_Area00000010.csv'))\n",
    "\n",
    "lens_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the rows into batches based on core count\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "process_count = int(cpu_count / 2)  # TODO consider making this larger, but using all CPUs has crashed\n",
    "generator = util.batch_list(list(df.iterrows()), process_count)\n",
    "batches = list(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11588 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot convert dictionary update sequence element #0 to a sequence",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRemoteTraceback\u001B[0m                           Traceback (most recent call last)",
      "\u001B[0;31mRemoteTraceback\u001B[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/data/bwedig/.conda/envs/pandeia/lib/python3.9/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/data/bwedig/.conda/envs/pandeia/lib/python3.9/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_29624/1901141095.py\", line 2, in generate_lens\n    row_dict = dict(row)\nTypeError: cannot convert dictionary update sequence element #0 to a sequence\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m tqdm(batches):\n\u001B[1;32m      3\u001B[0m     pool \u001B[38;5;241m=\u001B[39m Pool(processes\u001B[38;5;241m=\u001B[39mprocess_count) \n\u001B[0;32m----> 4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m row \u001B[38;5;129;01min\u001B[39;00m \u001B[43mpool\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgenerate_lens\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m      5\u001B[0m         lens_list\u001B[38;5;241m.\u001B[39mappend(row)\n",
      "File \u001B[0;32m/data/bwedig/.conda/envs/pandeia/lib/python3.9/multiprocessing/pool.py:364\u001B[0m, in \u001B[0;36mPool.map\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    359\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, iterable, chunksize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    360\u001B[0m     \u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m    361\u001B[0m \u001B[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001B[39;00m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;124;03m    in a list that is returned.\u001B[39;00m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[0;32m--> 364\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapstar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/data/bwedig/.conda/envs/pandeia/lib/python3.9/multiprocessing/pool.py:771\u001B[0m, in \u001B[0;36mApplyResult.get\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    769\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n\u001B[1;32m    770\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 771\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_value\n",
      "\u001B[0;31mTypeError\u001B[0m: cannot convert dictionary update sequence element #0 to a sequence"
     ]
    }
   ],
   "source": [
    "# process the batches\n",
    "for batch in tqdm(batches):\n",
    "    pool = Pool(processes=process_count) \n",
    "    for row in pool.map(generate_lens, batch):\n",
    "        lens_list.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle lens list\n",
    "with open(os.path.join(pickle_dir, 'skypy_output_lens_list'), 'ab') as results_file:\n",
    "    pickle.dump(lens_list, results_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandeia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
