{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "path = os.getcwd()\n",
    "while os.path.basename(os.path.normpath(path)) != 'mejiro':\n",
    "    path = os.path.dirname(path)\n",
    "repo_path = path\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from glob import glob\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from multiprocessing import Pool\n",
    "from hydra import initialize, compose\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from mejiro.plots import diagnostic_plot, plot\n",
    "from mejiro.utils import util\n",
    "from mejiro.helpers import pyhalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(tuple):\n",
    "    from mejiro.helpers import pyhalo\n",
    "    from mejiro.utils import util\n",
    "\n",
    "    # unpack tuple\n",
    "    (lens, pipeline_params, output_dir) = tuple\n",
    "\n",
    "    # unpack pipeline_params\n",
    "    subhalo_cone = pipeline_params['subhalo_cone']\n",
    "    los_normalization = pipeline_params['los_normalization']\n",
    "   \n",
    "    z_lens = round(list(lens.values())[0].z_lens, 2)\n",
    "    z_source = round(list(lens.values())[0].z_source, 2)\n",
    "\n",
    "    # randomly generate CDM subhalos\n",
    "    halo_tuple = pyhalo.generate_CDM_halos(z_lens, z_source, cone_opening_angle_arcsec=subhalo_cone, LOS_normalization=los_normalization)\n",
    "\n",
    "    # add this subhalo population to the lens for each filter\n",
    "    for band, band_lens in lens:\n",
    "        band_lens.add_subhalos(*halo_tuple)\n",
    "\n",
    "        pickle_target = os.path.join(output_dir, f'lens_with_subhalos_{lens.uid}_{band}')\n",
    "        util.pickle(pickle_target, band_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path='../../config'):\n",
    "    config = compose(config_name='config.yaml')  # overrides=['machine=uzay']\n",
    "\n",
    "array_dir, data_dir, repo_dir, pickle_dir = config.machine.array_dir, config.machine.data_dir, config.machine.repo_dir, config.machine.pickle_dir\n",
    "util.create_directory_if_not_exists(pickle_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split up the lenses into batches based on core count\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "process_count = cpu_count - 4\n",
    "\n",
    "# get bands\n",
    "bands = util.hydra_to_dict(config.pipeline)['band']\n",
    "\n",
    "# organize the pickles into a dict\n",
    "lens_dict = {}\n",
    "for band in bands:\n",
    "    # open pickled lens list\n",
    "    lens_list = util.unpickle(os.path.join(pickle_dir, f'01_skypy_output_lens_list_{band.lower()}'))\n",
    "    lens_dict[band] = lens_list\n",
    "\n",
    "# TODO this naming is dumb, fix it\n",
    "lenses = []\n",
    "# create a tuple for each lens\n",
    "for i, _ in enumerate(lens_list):\n",
    "    lens = {}\n",
    "    for band in bands:\n",
    "        lens[band] = lens_dict[band][i]\n",
    "    lenses.append(lens)\n",
    "\n",
    "# directory to write the lenses with subhalos to\n",
    "output_dir = os.path.join(pickle_dir, f'02_lenses_with_substructure')\n",
    "util.create_directory_if_not_exists(output_dir)\n",
    "util.clear_directory(output_dir)\n",
    "\n",
    "# tuple the parameters\n",
    "pipeline_params = util.hydra_to_dict(config.pipeline)\n",
    "tuple_list = []\n",
    "for i, _ in enumerate(lenses):\n",
    "    tuple_list.append((lenses[i], pipeline_params, output_dir))\n",
    "\n",
    "# batch\n",
    "generator = util.batch_list(tuple_list, process_count)\n",
    "batches = list(generator)\n",
    "\n",
    "# process the batches\n",
    "for batch in tqdm(batches):\n",
    "    pool = Pool(processes=process_count)\n",
    "    pool.map(add, batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandeia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
