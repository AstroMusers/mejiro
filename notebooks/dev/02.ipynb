{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "path = os.getcwd()\n",
    "while os.path.basename(os.path.normpath(path)) != 'mejiro':\n",
    "    path = os.path.dirname(path)\n",
    "repo_path = path\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.append(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from glob import glob\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from multiprocessing import Pool\n",
    "from hydra import initialize, compose\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from mejiro.plots import diagnostic_plot, plot\n",
    "from mejiro.utils import util\n",
    "from mejiro.helpers import pyhalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(tuple):\n",
    "    from mejiro.helpers import pyhalo\n",
    "    from mejiro.utils import util\n",
    "\n",
    "    # unpack tuple\n",
    "    (lens, pipeline_params, output_dir) = tuple\n",
    "\n",
    "    # unpack pipeline_params\n",
    "    subhalo_cone = pipeline_params['subhalo_cone']\n",
    "    los_normalization = pipeline_params['los_normalization']\n",
    "   \n",
    "    z_lens = round(list(lens.values())[0].z_lens, 2)\n",
    "    z_source = round(list(lens.values())[0].z_source, 2)\n",
    "\n",
    "    # randomly generate CDM subhalos\n",
    "    halo_tuple = pyhalo.generate_CDM_halos(z_lens, z_source, cone_opening_angle_arcsec=subhalo_cone, LOS_normalization=los_normalization)\n",
    "\n",
    "    # print(halo_tuple)\n",
    "\n",
    "    # add this subhalo population to the lens for each filter\n",
    "    for band, band_lens in lens.items():\n",
    "        band_lens.add_subhalos(*halo_tuple)\n",
    "\n",
    "        pickle_target = os.path.join(output_dir, f'lens_with_subhalos_{band_lens.uid}_{band}')\n",
    "        util.pickle(pickle_target, band_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path='../../config'):\n",
    "    config = compose(config_name='config.yaml')  # overrides=['machine=uzay']\n",
    "\n",
    "array_dir, data_dir, repo_dir, pickle_dir = config.machine.array_dir, config.machine.data_dir, config.machine.repo_dir, config.machine.pickle_dir\n",
    "util.create_directory_if_not_exists(pickle_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:50<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'uid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/data/bwedig/.conda/envs/mejiro/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/data/bwedig/.conda/envs/mejiro/lib/python3.10/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n  File \"/tmp/ipykernel_3719/1414554897.py\", line 24, in add\n    pickle_target = os.path.join(output_dir, f'lens_with_subhalos_{lens.uid}_{band}')\nAttributeError: 'dict' object has no attribute 'uid'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(batches):\n\u001b[1;32m     41\u001b[0m     pool \u001b[38;5;241m=\u001b[39m Pool(processes\u001b[38;5;241m=\u001b[39mprocess_count)\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43madd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/bwedig/.conda/envs/mejiro/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/bwedig/.conda/envs/mejiro/lib/python3.10/multiprocessing/pool.py:774\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 774\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'uid'"
     ]
    }
   ],
   "source": [
    "# split up the lenses into batches based on core count\n",
    "cpu_count = multiprocessing.cpu_count()\n",
    "process_count = cpu_count - 4\n",
    "\n",
    "# get bands\n",
    "bands = util.hydra_to_dict(config.pipeline)['band']\n",
    "\n",
    "# organize the pickles into a dict\n",
    "lens_dict = {}\n",
    "for band in bands:\n",
    "    # open pickled lens list\n",
    "    lens_list = util.unpickle(os.path.join(pickle_dir, f'01_skypy_output_lens_list_{band.lower()}'))\n",
    "    lens_dict[band] = lens_list\n",
    "\n",
    "# TODO this naming is dumb, fix it\n",
    "lenses = []\n",
    "# create a tuple for each lens\n",
    "for i, _ in enumerate(lens_list):\n",
    "    lens = {}\n",
    "    for band in bands:\n",
    "        lens[band] = lens_dict[band][i]\n",
    "    lenses.append(lens)\n",
    "\n",
    "# directory to write the lenses with subhalos to\n",
    "output_dir = os.path.join(pickle_dir, '02_lenses_with_substructure')\n",
    "util.create_directory_if_not_exists(output_dir)\n",
    "util.clear_directory(output_dir)\n",
    "\n",
    "# tuple the parameters\n",
    "pipeline_params = util.hydra_to_dict(config.pipeline)\n",
    "tuple_list = []\n",
    "for i, _ in enumerate(lenses):\n",
    "    tuple_list.append((lenses[i], pipeline_params, output_dir))\n",
    "\n",
    "# batch\n",
    "generator = util.batch_list(tuple_list, process_count)\n",
    "batches = list(generator)\n",
    "\n",
    "# process the batches\n",
    "for batch in tqdm(batches):\n",
    "    pool = Pool(processes=process_count)\n",
    "    pool.map(add, batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pandeia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
