{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "SURVEY = 'hltds_wide'\n",
    "\n",
    "if SURVEY == 'hltds_wide':\n",
    "    area = 19.04\n",
    "elif SURVEY == 'hltds_deep':\n",
    "    area = 4.2\n",
    "else:\n",
    "    raise ValueError('Invalid survey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from hydra import initialize, compose\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "# set paths to various directories based on the machine this code is being executed on\n",
    "try:\n",
    "    with initialize(version_base=None, config_path='config'):  \n",
    "        config = compose(config_name=f'config_{SURVEY}.yaml')  # overrides=['machine=uzay']\n",
    "except:\n",
    "    with initialize(version_base=None, config_path='../../config'):  \n",
    "        config = compose(config_name=f'config_{SURVEY}.yaml')  # overrides=['machine=uzay']\n",
    "\n",
    "array_dir, data_dir, figure_dir, pickle_dir, repo_dir  = config.machine.array_dir, config.machine.data_dir, config.machine.figure_dir, config.machine.pickle_dir, config.machine.repo_dir\n",
    "\n",
    "# enable use of local modules\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.append(repo_dir)\n",
    "\n",
    "# set matplotlib style\n",
    "plt.style.use(f'{repo_dir}/mejiro/mplstyle/science.mplstyle')\n",
    "\n",
    "from mejiro.utils import util\n",
    "\n",
    "survey_params = util.hydra_to_dict(config.survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_params = util.hydra_to_dict(config.pipeline)\n",
    "debugging = pipeline_params['debugging']\n",
    "\n",
    "if debugging:\n",
    "    pipeline_dir = f'{config.machine.pipeline_dir}_{SURVEY}'\n",
    "else:\n",
    "    pipeline_dir = config.machine.pipeline_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectable and candidate lens counts\n",
    "\n",
    "Number of detectable strong lenses per square degree of simulated area, candidate strong lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote combined CSV to /data/bwedig/mejiro/pipeline_hltds_wide/00/detectable_pop.csv\n",
      "Wrote combined CSV to /data/bwedig/mejiro/pipeline_hltds_wide/00/total_pop.csv\n"
     ]
    }
   ],
   "source": [
    "# combine CSVs from each run into one CSV\n",
    "data_dir = os.path.join(pipeline_dir, '00')\n",
    "\n",
    "detectable_csv = os.path.join(data_dir, 'detectable_pop.csv')\n",
    "util.delete_if_exists(detectable_csv)\n",
    "detectable_df = util.combine_all_csvs(data_dir, 'detectable', detectable_csv)\n",
    "\n",
    "if survey_params['total_population']:\n",
    "    total_csv = os.path.join(data_dir, 'total_pop.csv')\n",
    "    util.delete_if_exists(total_csv)\n",
    "    total_df = util.combine_all_csvs(data_dir, 'total', total_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 run(s) of 0.1 sq. deg. each gives 1.20 sq. deg. total\n"
     ]
    }
   ],
   "source": [
    "survey_area = survey_params['area']\n",
    "runs = survey_params['runs']\n",
    "\n",
    "total_area = survey_area * runs\n",
    "print(f'{runs} run(s) of {survey_area} sq. deg. each gives {total_area:.2f} sq. deg. total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055 detectable strong lenses\n",
      "146715 total candidate strong lenses\n",
      "Fraction of candidate strong lenses that are detectable: 0.01401\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(detectable_df)} detectable strong lenses')\n",
    "\n",
    "if survey_params['total_population']:\n",
    "    print(f'{len(total_df)} total candidate strong lenses')\n",
    "    fraction_detectable = len(detectable_df) / len(total_df)\n",
    "    print(f'Fraction of candidate strong lenses that are detectable: {fraction_detectable:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectable strong lenses per sq. deg.: 1712.50\n",
      "Candidate strong lenses per sq. deg.: 122262\n"
     ]
    }
   ],
   "source": [
    "det_per_sq_deg = len(detectable_df) / total_area\n",
    "print(f'Detectable strong lenses per sq. deg.: {det_per_sq_deg:.2f}')\n",
    "\n",
    "if survey_params['total_population']:\n",
    "    total_per_sq_deg = len(total_df) / total_area\n",
    "    print(f'Candidate strong lenses per sq. deg.: {round(total_per_sq_deg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectable strong lenses per exposure: 481.21\n"
     ]
    }
   ],
   "source": [
    "det_per_exposure = det_per_sq_deg * 0.281\n",
    "print(f'Detectable strong lenses per exposure: {det_per_exposure:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 characterizable strong lenses (SNR > 200)\n",
      "82.50 characterizable per sq. deg.\n",
      "Characterizable strong lenses per exposure: 23.18\n"
     ]
    }
   ],
   "source": [
    "snr_threshold = 200\n",
    "high_snr_df = detectable_df[detectable_df['snr'] > snr_threshold]\n",
    "high_snr_det_per_sq_deg = len(high_snr_df) / total_area\n",
    "high_snr_det_per_exposure = high_snr_det_per_sq_deg * 0.281\n",
    "\n",
    "print(f'{len(high_snr_df)} characterizable strong lenses (SNR > {snr_threshold})')\n",
    "print(f'{high_snr_det_per_sq_deg:.2f} characterizable per sq. deg.')\n",
    "print(f'Characterizable strong lenses per exposure: {high_snr_det_per_exposure:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32606 detectable strong lenses in hltds_wide\n",
      "1571 characterizable strong lenses in hltds_wide\n"
     ]
    }
   ],
   "source": [
    "print(f'{round(det_per_sq_deg * area)} detectable strong lenses in {SURVEY}')\n",
    "print(f'{round(high_snr_det_per_sq_deg * area)} characterizable strong lenses in {SURVEY}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mejiro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
