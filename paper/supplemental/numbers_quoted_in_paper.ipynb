{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from hydra import initialize, compose\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "# set paths to various directories based on the machine this code is being executed on\n",
    "with initialize(version_base=None, config_path='config'):\n",
    "    config = compose(config_name='config.yaml')  # , overrides=['machine=uzay']\n",
    "\n",
    "array_dir, data_dir, figure_dir, pickle_dir, repo_dir  = config.machine.array_dir, config.machine.data_dir, config.machine.figure_dir, config.machine.pickle_dir, config.machine.repo_dir\n",
    "\n",
    "# enable use of local modules\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.append(repo_dir)\n",
    "\n",
    "# set matplotlib style\n",
    "plt.style.use(f'{repo_dir}/mejiro/mplstyle/science.mplstyle')\n",
    "\n",
    "from mejiro.utils import util\n",
    "\n",
    "survey_params = util.hydra_to_dict(config.survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_params = util.hydra_to_dict(config.pipeline)\n",
    "debugging = pipeline_params['debugging']\n",
    "if debugging:\n",
    "    pipeline_dir = f'{config.machine.pipeline_dir}_dev'\n",
    "else:\n",
    "    pipeline_dir = config.machine.pipeline_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectable and candidate lens counts\n",
    "\n",
    "Number of detectable strong lenses per square degree of simulated area, candidate strong lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote combined CSV to /data/bwedig/mejiro/pipeline/00/detectable_pop.csv\n"
     ]
    }
   ],
   "source": [
    "# combine CSVs from each run into one CSV\n",
    "data_dir = os.path.join(pipeline_dir, '00')\n",
    "\n",
    "detectable_csv = os.path.join(data_dir, 'detectable_pop.csv')\n",
    "util.delete_if_exists(detectable_csv)\n",
    "detectable_df = util.combine_all_csvs(data_dir, 'detectable', detectable_csv)\n",
    "\n",
    "if survey_params['total_population']:\n",
    "    total_csv = os.path.join(data_dir, 'total_pop.csv')\n",
    "    util.delete_if_exists(total_csv)\n",
    "    total_df = util.combine_all_csvs(data_dir, 'total', total_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 run(s) of 0.5 sq. deg. each gives 450.00 sq. deg. total\n"
     ]
    }
   ],
   "source": [
    "survey_area = survey_params['area']\n",
    "runs = survey_params['runs']\n",
    "\n",
    "total_area = survey_area * runs\n",
    "print(f'{runs} run(s) of {survey_area} sq. deg. each gives {total_area:.2f} sq. deg. total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10343 detectable strong lenses\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(detectable_df)} detectable strong lenses')\n",
    "\n",
    "if survey_params['total_population']:\n",
    "    print(f'{len(total_df)} total candidate strong lenses')\n",
    "    fraction_detectable = len(detectable_df) / len(total_df)\n",
    "    print(f'Fraction of candidate strong lenses that are detectable: {fraction_detectable:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectable strong lenses per sq. deg.: 22.98\n"
     ]
    }
   ],
   "source": [
    "det_per_sq_deg = len(detectable_df) / total_area\n",
    "print(f'Detectable strong lenses per sq. deg.: {det_per_sq_deg:.2f}')\n",
    "\n",
    "if survey_params['total_population']:\n",
    "    total_per_sq_deg = len(total_df) / total_area\n",
    "    print(f'Candidate strong lenses per sq. deg.: {round(total_per_sq_deg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectable strong lenses per exposure: 6.46\n"
     ]
    }
   ],
   "source": [
    "det_per_exposure = det_per_sq_deg * 0.281\n",
    "print(f'Detectable strong lenses per exposure: {det_per_exposure:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much work are the various filters doing?\n",
    "\n",
    "`filter_1` is Einstein radius and half-light radius, and `filter_2` is SNR. The other detectability criteria are combined into the difference between candidate and detectable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if survey_params['total_population']:\n",
    "    filters = util.unpickle_all(data_dir, 'filtered_sample_')\n",
    "\n",
    "    num_filter_1 = np.sum([d['num_filter_1'] for d in filters])\n",
    "    num_filter_2 = np.sum([d['num_filter_2'] for d in filters])\n",
    "\n",
    "    percent_filter_1 = num_filter_1 / len(total_df) * 100\n",
    "    percent_filter_2 = num_filter_2 / len(total_df) * 100\n",
    "\n",
    "    print(f'{num_filter_1} ({percent_filter_1:.2f}%) candidate strong lenses caught in filter 1')\n",
    "    print(f'{num_filter_2} ({percent_filter_2:.2f}%) candidate strong lenses caught in filter 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation time\n",
    "\n",
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/bwedig/mejiro/pipeline/execution_times.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m json_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(pipeline_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexecution_times.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     execution_times \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      7\u001b[0m pprint(execution_times)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/bwedig/mejiro/pipeline/execution_times.json'"
     ]
    }
   ],
   "source": [
    "json_path = os.path.join(pipeline_dir, 'execution_times.json')\n",
    "\n",
    "import json\n",
    "with open(json_path, 'r') as f:\n",
    "    execution_times = json.load(f)\n",
    "\n",
    "pprint(execution_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pipeline execution time: 19180 seconds or 5:19:40 (5.33 hours)\n"
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "\n",
    "for script_name, times in execution_times.items():\n",
    "    h, m, s = times.split(':')\n",
    "    time = (int(h) * 3600) + (int(m) * 60) + int(s)\n",
    "    total_time += time\n",
    "\n",
    "print(f'Total pipeline execution time: {total_time} seconds or {datetime.timedelta(seconds=total_time)} ({total_time / 3600:.2f} hours)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'00': '45.75%',\n",
      " '01': '0.04%',\n",
      " '02': '0.53%',\n",
      " '03': '21.42%',\n",
      " '04': '32.11%',\n",
      " '05': '0.15%'}\n"
     ]
    }
   ],
   "source": [
    "percentage_dict = {}\n",
    "\n",
    "for script_name, times in execution_times.items():\n",
    "    h, m, s = times.split(':')\n",
    "    time = (int(h) * 3600) + (int(m) * 60) + int(s)\n",
    "    percentage = time / total_time * 100\n",
    "    percentage_dict[script_name] = f'{percentage:.2f}%'\n",
    "\n",
    "pprint(percentage_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey simulation time per square degree: 195.00 seconds or 0:03:15 (3.25 minutes)\n"
     ]
    }
   ],
   "source": [
    "h, m, s = execution_times['00'].split(':')\n",
    "survey_sim_seconds = (int(h) * 3600) + (int(m) * 60) + int(s)\n",
    "\n",
    "print(f'Survey simulation time per square degree: {survey_sim_seconds / total_area:.2f} seconds or {datetime.timedelta(seconds=round(survey_sim_seconds / total_area))} ({survey_sim_seconds / total_area / 60:.2f} minutes)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image simulation time per image: 9.99 seconds\n"
     ]
    }
   ],
   "source": [
    "total_image_sim = 0\n",
    "image_sim_scripts = ['01', '02', '03', '04']\n",
    "\n",
    "for script_name in image_sim_scripts:\n",
    "    h, m, s = execution_times[script_name].split(':')\n",
    "    time = (int(h) * 3600) + (int(m) * 60) + int(s)\n",
    "    total_image_sim += time\n",
    "\n",
    "print(f'Image simulation time per image: {total_image_sim / len(detectable_df):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': '0.07%', '02': '0.97%', '03': '39.60%', '04': '59.36%'}\n"
     ]
    }
   ],
   "source": [
    "image_sim_percentage_dict = {}\n",
    "\n",
    "for script_name in image_sim_scripts:\n",
    "    h, m, s = execution_times[script_name].split(':')\n",
    "    time = (int(h) * 3600) + (int(m) * 60) + int(s)\n",
    "    percentage = time / total_image_sim * 100\n",
    "    image_sim_percentage_dict[script_name] = f'{percentage:.2f}%'\n",
    "\n",
    "pprint(image_sim_percentage_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subhalo statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_list = util.unpickle_all(os.path.join(config.machine.dir_02, 'stats'), 'subhalo_stats_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_einstein_radii = [d['original_einstein_radius'] for d in stats_list]\n",
    "# adjusted_einstein_radii = [d['adjusted_einstein_radius'] for d in stats_list]\n",
    "# percent_change_einstein_radii = [d['percent_change_einstein_radius'] for d in stats_list]\n",
    "# effective_lensing_masses = [d['effective_lensing_mass'] for d in stats_list]\n",
    "# adjusted_lensing_masses = [d['adjusted_lensing_mass'] for d in stats_list]\n",
    "# percent_change_lensing_masses = [d['percent_change_lensing_mass'] for d in stats_list]\n",
    "# total_masses_subhalos_within_einstein_radius = [d['total_mass_subhalos_within_einstein_radius'] for d in stats_list]\n",
    "# total_subhalo_masses = [d['total_subhalo_mass'] for d in stats_list]\n",
    "# percent_subhalo_masses_within_einstein_radius = [d['percent_subhalo_mass_within_einstein_radius'] for d in stats_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(1, 3, figsize=(12, 3))\n",
    "# ax[0].hist(percent_change_einstein_radii)\n",
    "# ax[0].set_xlabel('Percent Change in Einstein Radius')\n",
    "# ax[0].set_ylabel('Number of Lenses')\n",
    "# ax[1].hist(percent_change_lensing_masses)\n",
    "# ax[1].set_xlabel('Percent Change in Lensing Mass')\n",
    "# ax[1].set_ylabel('Number of Lenses')\n",
    "# ax[2].hist(percent_subhalo_masses_within_einstein_radius)\n",
    "# ax[2].set_xlabel('Percent of Subhalo Mass within Einstein Radius')\n",
    "# ax[2].set_ylabel('Number of Lenses')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = np.mean(percent_change_einstein_radii)\n",
    "# stdev = np.std(percent_change_einstein_radii)\n",
    "\n",
    "# print(f'Mean percent change in Einstein radius: {mean:.2f}')\n",
    "# print(f'Standard deviation of percent change in Einstein radius: {stdev:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mejiro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
