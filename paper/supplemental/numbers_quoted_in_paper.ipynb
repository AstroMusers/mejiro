{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from hydra import initialize, compose\n",
    "import pickle\n",
    "from glob import glob\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "\n",
    "# set paths to various directories based on the machine this code is being executed on\n",
    "try:\n",
    "    with initialize(version_base=None, config_path='config'):\n",
    "        config = compose(config_name='config.yaml')  # overrides=['machine=uzay']\n",
    "except:\n",
    "    with initialize(version_base=None, config_path='../../config'):\n",
    "        config = compose(config_name='config.yaml')  # overrides=['machine=uzay']\n",
    "\n",
    "array_dir, data_dir, figure_dir, pickle_dir, repo_dir = config.machine.array_dir, config.machine.data_dir, config.machine.figure_dir, config.machine.pickle_dir, config.machine.repo_dir\n",
    "\n",
    "# enable use of local modules\n",
    "if repo_dir not in sys.path:\n",
    "    sys.path.append(repo_dir)\n",
    "\n",
    "# set matplotlib style\n",
    "plt.style.use(f'{repo_dir}/mejiro/mplstyle/science.mplstyle')\n",
    "\n",
    "from mejiro.utils import util\n",
    "\n",
    "survey_params = util.hydra_to_dict(config.survey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pipeline_dir: /data/bwedig/mejiro/pipeline\n"
     ]
    }
   ],
   "source": [
    "pipeline_params = util.hydra_to_dict(config.pipeline)\n",
    "debugging = pipeline_params['debugging']\n",
    "# debugging = True\n",
    "\n",
    "if debugging:\n",
    "    pipeline_dir = f'{config.machine.pipeline_dir}_dev'\n",
    "else:\n",
    "    pipeline_dir = config.machine.pipeline_dir\n",
    "\n",
    "print(f'pipeline_dir: {pipeline_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectable and candidate lens counts\n",
    "\n",
    "Number of detectable strong lenses per square degree of simulated area, candidate strong lenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote combined CSV to /data/bwedig/mejiro/pipeline/00/detectable_pop.csv\n",
      "Wrote combined CSV to /data/bwedig/mejiro/pipeline/00/total_pop.csv\n"
     ]
    }
   ],
   "source": [
    "# combine CSVs from each run into one CSV\n",
    "data_dir = os.path.join(pipeline_dir, '00')\n",
    "\n",
    "detectable_csv = os.path.join(data_dir, 'detectable_pop.csv')\n",
    "util.delete_if_exists(detectable_csv)\n",
    "detectable_df = util.combine_all_csvs(data_dir, 'detectable', detectable_csv)\n",
    "\n",
    "if survey_params['total_population']:\n",
    "    total_csv = os.path.join(data_dir, 'total_pop.csv')\n",
    "    util.delete_if_exists(total_csv)\n",
    "    total_df = util.combine_all_csvs(data_dir, 'total', total_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rows_with_inf_snr = detectable_df[np.isinf(detectable_df['snr'])]\n",
    "# print(rows_with_inf_snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows removed from detectable_df: 50\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of rows before filtering\n",
    "rows_before_detectable = len(detectable_df)\n",
    "\n",
    "# Remove rows with 'snr' as np.inf\n",
    "detectable_df = detectable_df[~np.isinf(detectable_df['snr'])]\n",
    "rows_removed_detectable = rows_before_detectable - len(detectable_df)\n",
    "print(f'Rows removed from detectable_df: {rows_removed_detectable}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342 run(s) of 0.5 sq. deg. each gives 171.00 sq. deg. total\n"
     ]
    }
   ],
   "source": [
    "survey_area = survey_params['area']\n",
    "runs = survey_params['runs']\n",
    "\n",
    "total_area = survey_area * runs\n",
    "print(f'{runs} run(s) of {survey_area} sq. deg. each gives {total_area:.2f} sq. deg. total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16214 detectable strong lenses\n",
      "1952101 total candidate strong lenses\n",
      "Fraction of candidate strong lenses that are detectable: 0.00831\n"
     ]
    }
   ],
   "source": [
    "print(f'{len(detectable_df)} detectable strong lenses')\n",
    "\n",
    "if survey_params['total_population']:\n",
    "    print(f'{len(total_df)} total candidate strong lenses')\n",
    "    fraction_detectable = len(detectable_df) / len(total_df)\n",
    "    print(f'Fraction of candidate strong lenses that are detectable: {fraction_detectable:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectable strong lenses per sq. deg.: 94.82\n",
      "Candidate strong lenses per sq. deg.: 11416\n"
     ]
    }
   ],
   "source": [
    "det_per_sq_deg = len(detectable_df) / total_area\n",
    "print(f'Detectable strong lenses per sq. deg.: {det_per_sq_deg:.2f}')\n",
    "\n",
    "if survey_params['total_population']:\n",
    "    total_per_sq_deg = len(total_df) / total_area\n",
    "    print(f'Candidate strong lenses per sq. deg.: {round(total_per_sq_deg)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detectable strong lenses per exposure: 26.64\n"
     ]
    }
   ],
   "source": [
    "det_per_exposure = det_per_sq_deg * 0.281\n",
    "print(f'Detectable strong lenses per exposure: {det_per_exposure:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 characterizable strong lenses (SNR > 200)\n",
      "0.28 characterizable per sq. deg.\n",
      "Characterizable strong lenses per exposure: 0.08\n"
     ]
    }
   ],
   "source": [
    "snr_threshold = 200\n",
    "high_snr_df = detectable_df[detectable_df['snr'] > snr_threshold]\n",
    "high_snr_det_per_sq_deg = len(high_snr_df) / total_area\n",
    "high_snr_det_per_exposure = high_snr_det_per_sq_deg * 0.281\n",
    "\n",
    "print(f'{len(high_snr_df)} characterizable strong lenses (SNR > {snr_threshold})')\n",
    "print(f'{high_snr_det_per_sq_deg:.2f} characterizable per sq. deg.')\n",
    "print(f'Characterizable strong lenses per exposure: {high_snr_det_per_exposure:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161192 detectable strong lenses in HLWAS\n",
      "477 characterizable strong lenses in HLWAS\n"
     ]
    }
   ],
   "source": [
    "# HLWAS\n",
    "print(f'{round(det_per_sq_deg * 1700)} detectable strong lenses in HLWAS')\n",
    "print(f'{round(high_snr_det_per_sq_deg * 1700)} characterizable strong lenses in HLWAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much work are the various filters doing?\n",
    "\n",
    "`filter_1` is Einstein radius and half-light radius, and `filter_2` is SNR. The other detectability criteria are combined into the difference between candidate and detectable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if survey_params['total_population']:\n",
    "#     filters = util.unpickle_all(data_dir, 'filtered_sample_')\n",
    "\n",
    "#     num_filter_1 = np.sum([d['num_filter_1'] for d in filters])\n",
    "#     num_filter_2 = np.sum([d['num_filter_2'] for d in filters])\n",
    "\n",
    "#     percent_filter_1 = num_filter_1 / len(total_df) * 100\n",
    "#     percent_filter_2 = num_filter_2 / len(total_df) * 100\n",
    "\n",
    "#     print(f'{num_filter_1} ({percent_filter_1:.2f}%) candidate strong lenses caught in filter 1')\n",
    "#     print(f'{num_filter_2} ({percent_filter_2:.2f}%) candidate strong lenses caught in filter 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computation time\n",
    "\n",
    "## Overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'00': '3 days, 6:53:20',\n",
      " '01': '0:00:57',\n",
      " '02': '0:21:26',\n",
      " '03': '19:21:21',\n",
      " '04': '0:32:39',\n",
      " '05': '0:01:37'}\n"
     ]
    }
   ],
   "source": [
    "json_path = os.path.join(pipeline_dir, 'execution_times.json')\n",
    "\n",
    "import json\n",
    "\n",
    "with open(json_path, 'r') as f:\n",
    "    execution_times = json.load(f)\n",
    "\n",
    "pprint(execution_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pipeline execution time: 357080 seconds or 4 days, 3:11:20 (99.19 hours)\n"
     ]
    }
   ],
   "source": [
    "total_time = 0\n",
    "\n",
    "for script_name, times in execution_times.items():\n",
    "    h, m, s = times.split(':')\n",
    "    if 'days' in h:\n",
    "        d, h = h.split('days, ')\n",
    "        h = int(d) * 24 + int(h)\n",
    "    elif 'day' in h:\n",
    "        d, h = h.split('day, ')\n",
    "        h = int(d) * 24 + int(h)\n",
    "    time = (int(h) * 3600) + (int(m) * 60) + int(s)\n",
    "    total_time += time\n",
    "\n",
    "print(\n",
    "    f'Total pipeline execution time: {total_time} seconds or {datetime.timedelta(seconds=total_time)} ({total_time / 3600:.2f} hours)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'00': '79.53%',\n",
      " '01': '0.02%',\n",
      " '02': '0.36%',\n",
      " '03': '19.51%',\n",
      " '04': '0.55%',\n",
      " '05': '0.03%'}\n"
     ]
    }
   ],
   "source": [
    "percentage_dict = {}\n",
    "\n",
    "for script_name, times in execution_times.items():\n",
    "    h, m, s = times.split(':')\n",
    "    if 'days' in h:\n",
    "        d, h = h.split('days, ')\n",
    "        h = int(d) * 24 + int(h)\n",
    "    elif 'day' in h:\n",
    "        d, h = h.split('day, ')\n",
    "        h = int(d) * 24 + int(h)\n",
    "    time = (int(h) * 3600) + (int(m) * 60) + int(s)\n",
    "    percentage = time / total_time * 100\n",
    "    percentage_dict[script_name] = f'{percentage:.2f}%'\n",
    "\n",
    "pprint(percentage_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survey simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey simulation time per square degree: 1660.82 seconds or 0:27:41 (27.68 minutes)\n"
     ]
    }
   ],
   "source": [
    "h, m, s = execution_times['00'].split(':')\n",
    "if 'days' in h:\n",
    "    d, h = h.split('days, ')\n",
    "    h = int(d) * 24 + int(h)\n",
    "elif 'day' in h:\n",
    "    d, h = h.split('day, ')\n",
    "    h = int(d) * 24 + int(h)\n",
    "survey_sim_seconds = (int(h) * 3600) + (int(m) * 60) + int(s)\n",
    "\n",
    "print(\n",
    "    f'Survey simulation time per square degree: {survey_sim_seconds / total_area:.2f} seconds or {datetime.timedelta(seconds=round(survey_sim_seconds / total_area))} ({survey_sim_seconds / total_area / 60:.2f} minutes)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image simulation time per image: 4.50 seconds\n"
     ]
    }
   ],
   "source": [
    "total_image_sim = 0\n",
    "image_sim_scripts = ['01', '02', '03', '04']\n",
    "\n",
    "for script_name in image_sim_scripts:\n",
    "    h, m, s = execution_times[script_name].split(':')\n",
    "    if 'day' in h:\n",
    "        d, h = h.split('day, ')\n",
    "        h = int(d) * 24 + int(h)\n",
    "    time = (int(h) * 3600) + (int(m) * 60) + int(s)\n",
    "    total_image_sim += time\n",
    "\n",
    "print(f'Image simulation time per image: {total_image_sim / len(detectable_df):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': '0.08%', '02': '1.76%', '03': '95.48%', '04': '2.68%'}\n"
     ]
    }
   ],
   "source": [
    "image_sim_percentage_dict = {}\n",
    "\n",
    "for script_name in image_sim_scripts:\n",
    "    h, m, s = execution_times[script_name].split(':')\n",
    "    if 'day' in h:\n",
    "        d, h = h.split('day, ')\n",
    "        h = int(d) * 24 + int(h)\n",
    "    time = (int(h) * 3600) + (int(m) * 60) + int(s)\n",
    "    percentage = time / total_image_sim * 100\n",
    "    image_sim_percentage_dict[script_name] = f'{percentage:.2f}%'\n",
    "\n",
    "pprint(image_sim_percentage_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subhalo statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats_list = util.unpickle_all(os.path.join(config.machine.dir_02, 'stats'), 'subhalo_stats_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original_einstein_radii = [d['original_einstein_radius'] for d in stats_list]\n",
    "# adjusted_einstein_radii = [d['adjusted_einstein_radius'] for d in stats_list]\n",
    "# percent_change_einstein_radii = [d['percent_change_einstein_radius'] for d in stats_list]\n",
    "# effective_lensing_masses = [d['effective_lensing_mass'] for d in stats_list]\n",
    "# adjusted_lensing_masses = [d['adjusted_lensing_mass'] for d in stats_list]\n",
    "# percent_change_lensing_masses = [d['percent_change_lensing_mass'] for d in stats_list]\n",
    "# total_masses_subhalos_within_einstein_radius = [d['total_mass_subhalos_within_einstein_radius'] for d in stats_list]\n",
    "# total_subhalo_masses = [d['total_subhalo_mass'] for d in stats_list]\n",
    "# percent_subhalo_masses_within_einstein_radius = [d['percent_subhalo_mass_within_einstein_radius'] for d in stats_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f, ax = plt.subplots(1, 3, figsize=(12, 3))\n",
    "# ax[0].hist(percent_change_einstein_radii)\n",
    "# ax[0].set_xlabel('Percent Change in Einstein Radius')\n",
    "# ax[0].set_ylabel('Number of Lenses')\n",
    "# ax[1].hist(percent_change_lensing_masses)\n",
    "# ax[1].set_xlabel('Percent Change in Lensing Mass')\n",
    "# ax[1].set_ylabel('Number of Lenses')\n",
    "# ax[2].hist(percent_subhalo_masses_within_einstein_radius)\n",
    "# ax[2].set_xlabel('Percent of Subhalo Mass within Einstein Radius')\n",
    "# ax[2].set_ylabel('Number of Lenses')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = np.mean(percent_change_einstein_radii)\n",
    "# stdev = np.std(percent_change_einstein_radii)\n",
    "\n",
    "# print(f'Mean percent change in Einstein radius: {mean:.2f}')\n",
    "# print(f'Standard deviation of percent change in Einstein radius: {stdev:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mejiro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
